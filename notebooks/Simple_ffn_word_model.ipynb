{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple feed forward model\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "- [Read data](#Read-data)\n",
    "- [Prepare data](#Prepare-data)\n",
    "- [Create and train model](#Create-and-train-model)\n",
    "- [Test on unseen data](#Test-on-unseen-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "MODULES_PATH = '../modules'\n",
    "MODELS_PATH = '../models'\n",
    "DATA_PATH = '../data'\n",
    "\n",
    "sys.path.append(MODULES_PATH)\n",
    "from data import flatten_data, prepare_training_data, prepare_test_data, \\\n",
    "                    raise_one_level\n",
    "from models import simple_ffn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH,'sentences.json'),'r') as datafile:\n",
    "    sentences = json.load(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = pd.read_csv(os.path.join(DATA_PATH,'training_data.csv'), \n",
    "                        index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>class</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\r'b\"Werkende aansoekers: Dui asseblief jou ba...</td>\n",
       "      <td>af</td>\n",
       "      <td>(1124200875659 AM) GEMS_APP(AFRIKAANS).txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r'b'Uitstekende gesondheidsorgvoordele teen b...</td>\n",
       "      <td>af</td>\n",
       "      <td>(3102010124331 PM) FINAL MB AFRIKAANS.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\r'b'Uitstekende gesondheidsorgvoordele teen b...</td>\n",
       "      <td>af</td>\n",
       "      <td>(3172010120044 PM) FINAL MB AFRIKAANS.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\r'b'Om alle staatsdienswerknemers van gelyke ...</td>\n",
       "      <td>af</td>\n",
       "      <td>(32201090225 AM) REO Afrikaans met benefit sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\r'b\"Sou u na 1 Januarie van 'n jaar aansluit,...</td>\n",
       "      <td>af</td>\n",
       "      <td>(42200942018 PM) NIMAS_Appli. FormAfr_PD7023.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body class  \\\n",
       "0  \\r'b\"Werkende aansoekers: Dui asseblief jou ba...    af   \n",
       "1  \\r'b'Uitstekende gesondheidsorgvoordele teen b...    af   \n",
       "2  \\r'b'Uitstekende gesondheidsorgvoordele teen b...    af   \n",
       "3  \\r'b'Om alle staatsdienswerknemers van gelyke ...    af   \n",
       "4  \\r'b\"Sou u na 1 Januarie van 'n jaar aansluit,...    af   \n",
       "\n",
       "                                               title  \n",
       "0         (1124200875659 AM) GEMS_APP(AFRIKAANS).txt  \n",
       "1          (3102010124331 PM) FINAL MB AFRIKAANS.txt  \n",
       "2          (3172010120044 PM) FINAL MB AFRIKAANS.txt  \n",
       "3  (32201090225 AM) REO Afrikaans met benefit sch...  \n",
       "4   (42200942018 PM) NIMAS_Appli. FormAfr_PD7023.txt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_flat = raise_one_level(sentences)\n",
    "sentences_df = pd.DataFrame(sentences_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora_train, corpora_test, labels_train, labels_test = train_test_split(\n",
    "                                                        sentences_df['body'],\n",
    "                                                        sentences_df['class'],\n",
    "                                                        test_size=0.75,\n",
    "                                                        random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "for i in range(1,4):\n",
    "    print(i+1)\n",
    "\n",
    "    document_matrix, labels, pipeline_instance = prepare_training_data(corpora_train, labels_train, (i,i), 'word')\n",
    "    training_data.append({'document_matrix': document_matrix, 'labels': labels, 'pipeline_instance': pipeline_instance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10139, 78956), (10139, 11), Pipeline(memory=None,\n",
       "      steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None, vocabulary=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True))]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]['document_matrix'].shape, training_data[0]['labels'].shape, training_data[0]['pipeline_instance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10139, 78956)\n",
      "(10139, 269370)\n",
      "(10139, 360124)\n"
     ]
    }
   ],
   "source": [
    "for i in training_data:\n",
    "    print(i['document_matrix'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0083</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>011</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>012</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01636</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>019</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>020</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>021</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>022</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>023</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>024</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>028</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03032410461005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwiolwa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwipida</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwipikwa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwipotso</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwipuka</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwishumisa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwishumiswa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwishumuswa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwiswa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwitakalelwa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwitatamennde</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwitentsini</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwitewa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwithu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwitshele</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwitsireledzi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwitumbu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwivhangakhombo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwivhangi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwivhili</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwivhumbeo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwivhuya</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwiwe</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwiwo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwohe</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwongo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwothe</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78956 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0    1    2    3    4\n",
       "00               0.0  0.0  0.0  0.0  0.0\n",
       "000              0.0  0.0  0.0  0.0  0.0\n",
       "0001             0.0  0.0  0.0  0.0  0.0\n",
       "001              0.0  0.0  0.0  0.0  0.0\n",
       "004              0.0  0.0  0.0  0.0  0.0\n",
       "006              0.0  0.0  0.0  0.0  0.0\n",
       "007              0.0  0.0  0.0  0.0  0.0\n",
       "008              0.0  0.0  0.0  0.0  0.0\n",
       "0083             0.0  0.0  0.0  0.0  0.0\n",
       "01               0.0  0.0  0.0  0.0  0.0\n",
       "011              0.0  0.0  0.0  0.0  0.0\n",
       "012              0.0  0.0  0.0  0.0  0.0\n",
       "013              0.0  0.0  0.0  0.0  0.0\n",
       "0134             0.0  0.0  0.0  0.0  0.0\n",
       "0148             0.0  0.0  0.0  0.0  0.0\n",
       "015              0.0  0.0  0.0  0.0  0.0\n",
       "01636            0.0  0.0  0.0  0.0  0.0\n",
       "018              0.0  0.0  0.0  0.0  0.0\n",
       "019              0.0  0.0  0.0  0.0  0.0\n",
       "02               0.0  0.0  0.0  0.0  0.0\n",
       "020              0.0  0.0  0.0  0.0  0.0\n",
       "021              0.0  0.0  0.0  0.0  0.0\n",
       "022              0.0  0.0  0.0  0.0  0.0\n",
       "023              0.0  0.0  0.0  0.0  0.0\n",
       "024              0.0  0.0  0.0  0.0  0.0\n",
       "026              0.0  0.0  0.0  0.0  0.0\n",
       "028              0.0  0.0  0.0  0.0  0.0\n",
       "03               0.0  0.0  0.0  0.0  0.0\n",
       "030              0.0  0.0  0.0  0.0  0.0\n",
       "03032410461005   0.0  0.0  0.0  0.0  0.0\n",
       "...              ...  ...  ...  ...  ...\n",
       "zwiolwa          0.0  0.0  0.0  0.0  0.0\n",
       "zwipida          0.0  0.0  0.0  0.0  0.0\n",
       "zwipikwa         0.0  0.0  0.0  0.0  0.0\n",
       "zwipotso         0.0  0.0  0.0  0.0  0.0\n",
       "zwipuka          0.0  0.0  0.0  0.0  0.0\n",
       "zwishumisa       0.0  0.0  0.0  0.0  0.0\n",
       "zwishumiswa      0.0  0.0  0.0  0.0  0.0\n",
       "zwishumuswa      0.0  0.0  0.0  0.0  0.0\n",
       "zwiswa           0.0  0.0  0.0  0.0  0.0\n",
       "zwitakalelwa     0.0  0.0  0.0  0.0  0.0\n",
       "zwitatamennde    0.0  0.0  0.0  0.0  0.0\n",
       "zwitentsini      0.0  0.0  0.0  0.0  0.0\n",
       "zwitewa          0.0  0.0  0.0  0.0  0.0\n",
       "zwithu           0.0  0.0  0.0  0.0  0.0\n",
       "zwitshele        0.0  0.0  0.0  0.0  0.0\n",
       "zwitsireledzi    0.0  0.0  0.0  0.0  0.0\n",
       "zwitumbu         0.0  0.0  0.0  0.0  0.0\n",
       "zwivhangakhombo  0.0  0.0  0.0  0.0  0.0\n",
       "zwivhangi        0.0  0.0  0.0  0.0  0.0\n",
       "zwivhili         0.0  0.0  0.0  0.0  0.0\n",
       "zwivhumbeo       0.0  0.0  0.0  0.0  0.0\n",
       "zwivhuya         0.0  0.0  0.0  0.0  0.0\n",
       "zwiwe            0.0  0.0  0.0  0.0  0.0\n",
       "zwiwo            0.0  0.0  0.0  0.0  0.0\n",
       "zwo              0.0  0.0  0.0  0.0  0.0\n",
       "zwohe            0.0  0.0  0.0  0.0  0.0\n",
       "zwone            0.0  0.0  0.0  0.0  0.0\n",
       "zwongo           0.0  0.0  0.0  0.0  0.0\n",
       "zwothe           0.0  0.0  0.0  0.0  0.0\n",
       "zyl              0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[78956 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]['document_matrix'].head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join(DATA_PATH, 'pipeline_instance.pickle'),'wb') as datafile:\n",
    "#         pickle.dump(pipeline_instance, datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [128]\n",
    "activations = ['relu']\n",
    "dropout = [0.15]\n",
    "attention = [128]\n",
    "max(len(layers), len(activations), len(dropout),  len(attention))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 360124)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          46096000    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_probs (Dense)         (None, 128)          16512       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attention_mul (Multiply)        (None, 128)          0           batch_normalization_4[0][0]      \n",
      "                                                                 attention_probs[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 11)           1419        attention_mul[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 11)           0           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,114,443\n",
      "Trainable params: 46,114,187\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = simple_ffn(document_matrix, labels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412, 79733)\n",
      "Train on 370 samples, validate on 42 samples\n",
      "Epoch 1/100\n",
      "370/370 [==============================] - 11s 28ms/step - loss: 2.3970 - acc: 0.2946 - val_loss: 2.3954 - val_acc: 0.7381\n",
      "Epoch 2/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 2.3935 - acc: 0.8297 - val_loss: 2.3927 - val_acc: 0.8333\n",
      "Epoch 3/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 2.3899 - acc: 0.8649 - val_loss: 2.3896 - val_acc: 0.8333\n",
      "Epoch 4/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.3859 - acc: 0.9081 - val_loss: 2.3861 - val_acc: 0.8810\n",
      "Epoch 5/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 2.3811 - acc: 0.9189 - val_loss: 2.3821 - val_acc: 0.9048\n",
      "Epoch 6/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 2.3762 - acc: 0.9081 - val_loss: 2.3778 - val_acc: 0.9048\n",
      "Epoch 7/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.3707 - acc: 0.9189 - val_loss: 2.3731 - val_acc: 0.9048\n",
      "Epoch 8/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.3653 - acc: 0.9405 - val_loss: 2.3683 - val_acc: 0.9048\n",
      "Epoch 9/100\n",
      "370/370 [==============================] - 8s 20ms/step - loss: 2.3585 - acc: 0.9216 - val_loss: 2.3630 - val_acc: 0.9048\n",
      "Epoch 10/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 2.3522 - acc: 0.9189 - val_loss: 2.3572 - val_acc: 0.9048\n",
      "Epoch 11/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 2.3460 - acc: 0.9162 - val_loss: 2.3509 - val_acc: 0.9048\n",
      "Epoch 12/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.3363 - acc: 0.9216 - val_loss: 2.3441 - val_acc: 0.9048\n",
      "Epoch 13/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.3302 - acc: 0.9108 - val_loss: 2.3361 - val_acc: 0.9048\n",
      "Epoch 14/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.3172 - acc: 0.9135 - val_loss: 2.3263 - val_acc: 0.9048\n",
      "Epoch 15/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 2.3090 - acc: 0.8946 - val_loss: 2.3135 - val_acc: 0.9048\n",
      "Epoch 16/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 2.2944 - acc: 0.9027 - val_loss: 2.2952 - val_acc: 0.8810\n",
      "Epoch 17/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.2754 - acc: 0.8865 - val_loss: 2.2751 - val_acc: 0.8333\n",
      "Epoch 18/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 2.2594 - acc: 0.8730 - val_loss: 2.2579 - val_acc: 0.8333\n",
      "Epoch 19/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 2.2474 - acc: 0.8568 - val_loss: 2.2416 - val_acc: 0.8333\n",
      "Epoch 20/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.2287 - acc: 0.8622 - val_loss: 2.2272 - val_acc: 0.8333\n",
      "Epoch 21/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.2152 - acc: 0.8622 - val_loss: 2.2130 - val_acc: 0.8333\n",
      "Epoch 22/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 2.2084 - acc: 0.8405 - val_loss: 2.1973 - val_acc: 0.8333\n",
      "Epoch 23/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 2.1935 - acc: 0.8297 - val_loss: 2.1835 - val_acc: 0.8333\n",
      "Epoch 24/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 2.1692 - acc: 0.8270 - val_loss: 2.1712 - val_acc: 0.8095\n",
      "Epoch 25/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.1464 - acc: 0.8243 - val_loss: 2.1608 - val_acc: 0.8095\n",
      "Epoch 26/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 2.1432 - acc: 0.8162 - val_loss: 2.1511 - val_acc: 0.8095\n",
      "Epoch 27/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 2.1150 - acc: 0.8270 - val_loss: 2.1425 - val_acc: 0.8095\n",
      "Epoch 28/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.1116 - acc: 0.8216 - val_loss: 2.1363 - val_acc: 0.8095\n",
      "Epoch 29/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 2.0819 - acc: 0.8378 - val_loss: 2.1297 - val_acc: 0.8095\n",
      "Epoch 30/100\n",
      "370/370 [==============================] - 6s 17ms/step - loss: 2.0892 - acc: 0.8027 - val_loss: 2.1239 - val_acc: 0.8095\n",
      "Epoch 31/100\n",
      "370/370 [==============================] - 6s 18ms/step - loss: 2.0837 - acc: 0.8081 - val_loss: 2.1183 - val_acc: 0.8095\n",
      "Epoch 32/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.0825 - acc: 0.7973 - val_loss: 2.1134 - val_acc: 0.8095\n",
      "Epoch 33/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.0460 - acc: 0.8351 - val_loss: 2.1087 - val_acc: 0.8095\n",
      "Epoch 34/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 2.0491 - acc: 0.8054 - val_loss: 2.1035 - val_acc: 0.7857\n",
      "Epoch 35/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 2.0443 - acc: 0.8135 - val_loss: 2.0991 - val_acc: 0.7857\n",
      "Epoch 36/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 2.0204 - acc: 0.8378 - val_loss: 2.0953 - val_acc: 0.7857\n",
      "Epoch 37/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 2.0294 - acc: 0.7919 - val_loss: 2.0920 - val_acc: 0.7857\n",
      "Epoch 38/100\n",
      "370/370 [==============================] - 6s 17ms/step - loss: 2.0132 - acc: 0.8297 - val_loss: 2.0893 - val_acc: 0.7857\n",
      "Epoch 39/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 1.9982 - acc: 0.8027 - val_loss: 2.0852 - val_acc: 0.7857\n",
      "Epoch 40/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 2.0014 - acc: 0.8135 - val_loss: 2.0811 - val_acc: 0.7857\n",
      "Epoch 41/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 1.9997 - acc: 0.8000 - val_loss: 2.0771 - val_acc: 0.7857\n",
      "Epoch 42/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.9887 - acc: 0.7838 - val_loss: 2.0723 - val_acc: 0.7857\n",
      "Epoch 43/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.9793 - acc: 0.8000 - val_loss: 2.0679 - val_acc: 0.7857\n",
      "Epoch 44/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.9545 - acc: 0.8135 - val_loss: 2.0644 - val_acc: 0.7857\n",
      "Epoch 45/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.9601 - acc: 0.8000 - val_loss: 2.0594 - val_acc: 0.7857\n",
      "Epoch 46/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 1.9492 - acc: 0.8270 - val_loss: 2.0557 - val_acc: 0.7857\n",
      "Epoch 47/100\n",
      "370/370 [==============================] - 7s 19ms/step - loss: 1.9430 - acc: 0.8000 - val_loss: 2.0510 - val_acc: 0.7857\n",
      "Epoch 48/100\n",
      "370/370 [==============================] - 6s 17ms/step - loss: 1.9326 - acc: 0.8243 - val_loss: 2.0474 - val_acc: 0.7857\n",
      "Epoch 49/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.9345 - acc: 0.8000 - val_loss: 2.0412 - val_acc: 0.7857\n",
      "Epoch 50/100\n",
      "370/370 [==============================] - 6s 17ms/step - loss: 1.9251 - acc: 0.8081 - val_loss: 2.0365 - val_acc: 0.7857\n",
      "Epoch 51/100\n",
      "370/370 [==============================] - 7s 19ms/step - loss: 1.9382 - acc: 0.7865 - val_loss: 2.0312 - val_acc: 0.7857\n",
      "Epoch 52/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 1.9206 - acc: 0.8054 - val_loss: 2.0277 - val_acc: 0.8095\n",
      "Epoch 53/100\n",
      "370/370 [==============================] - 7s 18ms/step - loss: 1.8987 - acc: 0.8108 - val_loss: 2.0238 - val_acc: 0.8095\n",
      "Epoch 54/100\n",
      "370/370 [==============================] - 7s 19ms/step - loss: 1.8788 - acc: 0.8162 - val_loss: 2.0200 - val_acc: 0.8095\n",
      "Epoch 55/100\n",
      "370/370 [==============================] - 7s 18ms/step - loss: 1.9086 - acc: 0.7730 - val_loss: 2.0160 - val_acc: 0.8095\n",
      "Epoch 56/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 1.8873 - acc: 0.8000 - val_loss: 2.0109 - val_acc: 0.8095\n",
      "Epoch 57/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.8756 - acc: 0.7892 - val_loss: 2.0066 - val_acc: 0.8095\n",
      "Epoch 58/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 1.8704 - acc: 0.8054 - val_loss: 2.0021 - val_acc: 0.8095\n",
      "Epoch 59/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.8478 - acc: 0.8216 - val_loss: 1.9973 - val_acc: 0.8095\n",
      "Epoch 60/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.8453 - acc: 0.7919 - val_loss: 1.9920 - val_acc: 0.8095\n",
      "Epoch 61/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.8516 - acc: 0.8027 - val_loss: 1.9859 - val_acc: 0.8095\n",
      "Epoch 62/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.8393 - acc: 0.8081 - val_loss: 1.9805 - val_acc: 0.8095\n",
      "Epoch 63/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 1.8397 - acc: 0.7973 - val_loss: 1.9746 - val_acc: 0.8095\n",
      "Epoch 64/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.8287 - acc: 0.8081 - val_loss: 1.9688 - val_acc: 0.8095\n",
      "Epoch 65/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.8326 - acc: 0.7730 - val_loss: 1.9627 - val_acc: 0.8095\n",
      "Epoch 66/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.8192 - acc: 0.7973 - val_loss: 1.9569 - val_acc: 0.8095\n",
      "Epoch 67/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.8218 - acc: 0.7703 - val_loss: 1.9510 - val_acc: 0.8095\n",
      "Epoch 68/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 1.8031 - acc: 0.8081 - val_loss: 1.9454 - val_acc: 0.8095\n",
      "Epoch 69/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.7965 - acc: 0.7892 - val_loss: 1.9402 - val_acc: 0.8095\n",
      "Epoch 70/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.8032 - acc: 0.7865 - val_loss: 1.9343 - val_acc: 0.8095\n",
      "Epoch 71/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.8018 - acc: 0.8081 - val_loss: 1.9295 - val_acc: 0.8095\n",
      "Epoch 72/100\n",
      "370/370 [==============================] - 7s 19ms/step - loss: 1.7756 - acc: 0.8189 - val_loss: 1.9254 - val_acc: 0.8095\n",
      "Epoch 73/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.7955 - acc: 0.7811 - val_loss: 1.9201 - val_acc: 0.8095\n",
      "Epoch 74/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.7779 - acc: 0.7919 - val_loss: 1.9154 - val_acc: 0.8095\n",
      "Epoch 75/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.7528 - acc: 0.8054 - val_loss: 1.9116 - val_acc: 0.8095\n",
      "Epoch 76/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 1.7768 - acc: 0.7676 - val_loss: 1.9069 - val_acc: 0.8095\n",
      "Epoch 77/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 1.7543 - acc: 0.8027 - val_loss: 1.9034 - val_acc: 0.8095\n",
      "Epoch 78/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.7581 - acc: 0.7865 - val_loss: 1.8990 - val_acc: 0.8095\n",
      "Epoch 79/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.7613 - acc: 0.7784 - val_loss: 1.8951 - val_acc: 0.8095\n",
      "Epoch 80/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.7329 - acc: 0.8135 - val_loss: 1.8916 - val_acc: 0.8095\n",
      "Epoch 81/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.7281 - acc: 0.7973 - val_loss: 1.8889 - val_acc: 0.8095\n",
      "Epoch 82/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 1.7674 - acc: 0.7730 - val_loss: 1.8839 - val_acc: 0.8095\n",
      "Epoch 83/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.7461 - acc: 0.7865 - val_loss: 1.8799 - val_acc: 0.8095\n",
      "Epoch 84/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.7489 - acc: 0.7595 - val_loss: 1.8753 - val_acc: 0.8095\n",
      "Epoch 85/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.7223 - acc: 0.7757 - val_loss: 1.8717 - val_acc: 0.8095\n",
      "Epoch 86/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 1.7328 - acc: 0.8027 - val_loss: 1.8688 - val_acc: 0.8095\n",
      "Epoch 87/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.7268 - acc: 0.7730 - val_loss: 1.8656 - val_acc: 0.8095\n",
      "Epoch 88/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.6995 - acc: 0.8108 - val_loss: 1.8634 - val_acc: 0.8095\n",
      "Epoch 89/100\n",
      "370/370 [==============================] - 5s 14ms/step - loss: 1.6954 - acc: 0.8108 - val_loss: 1.8605 - val_acc: 0.8095\n",
      "Epoch 90/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.6943 - acc: 0.8297 - val_loss: 1.8581 - val_acc: 0.8095\n",
      "Epoch 91/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.7034 - acc: 0.7973 - val_loss: 1.8541 - val_acc: 0.8095\n",
      "Epoch 92/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.7210 - acc: 0.7973 - val_loss: 1.8510 - val_acc: 0.8095\n",
      "Epoch 93/100\n",
      "370/370 [==============================] - 7s 19ms/step - loss: 1.7014 - acc: 0.7973 - val_loss: 1.8480 - val_acc: 0.8095\n",
      "Epoch 94/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.6741 - acc: 0.8216 - val_loss: 1.8455 - val_acc: 0.8095\n",
      "Epoch 95/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.6849 - acc: 0.7946 - val_loss: 1.8423 - val_acc: 0.8095\n",
      "Epoch 96/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.6924 - acc: 0.7838 - val_loss: 1.8390 - val_acc: 0.8095\n",
      "Epoch 97/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.6465 - acc: 0.8189 - val_loss: 1.8373 - val_acc: 0.8095\n",
      "Epoch 98/100\n",
      "370/370 [==============================] - 5s 15ms/step - loss: 1.6669 - acc: 0.8243 - val_loss: 1.8357 - val_acc: 0.8095\n",
      "Epoch 99/100\n",
      "370/370 [==============================] - 6s 16ms/step - loss: 1.6575 - acc: 0.8189 - val_loss: 1.8322 - val_acc: 0.8095\n",
      "Epoch 100/100\n",
      "370/370 [==============================] - 6s 15ms/step - loss: 1.6781 - acc: 0.7622 - val_loss: 1.8284 - val_acc: 0.8095\n",
      "(412, 281933)\n",
      "Train on 370 samples, validate on 42 samples\n",
      "Epoch 1/100\n",
      "370/370 [==============================] - 27s 73ms/step - loss: 2.3972 - acc: 0.3595 - val_loss: 2.3962 - val_acc: 0.6190\n",
      "Epoch 2/100\n",
      "370/370 [==============================] - 20s 55ms/step - loss: 2.3929 - acc: 0.8459 - val_loss: 2.3941 - val_acc: 0.6905\n",
      "Epoch 3/100\n",
      "370/370 [==============================] - 20s 55ms/step - loss: 2.3878 - acc: 0.8946 - val_loss: 2.3915 - val_acc: 0.7143\n",
      "Epoch 4/100\n",
      "370/370 [==============================] - 22s 59ms/step - loss: 2.3822 - acc: 0.8703 - val_loss: 2.3887 - val_acc: 0.7143\n",
      "Epoch 5/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.3759 - acc: 0.8919 - val_loss: 2.3859 - val_acc: 0.7381\n",
      "Epoch 6/100\n",
      "370/370 [==============================] - 20s 55ms/step - loss: 2.3685 - acc: 0.9081 - val_loss: 2.3831 - val_acc: 0.7381\n",
      "Epoch 7/100\n",
      "370/370 [==============================] - 20s 54ms/step - loss: 2.3606 - acc: 0.8892 - val_loss: 2.3805 - val_acc: 0.7619\n",
      "Epoch 8/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.3526 - acc: 0.9162 - val_loss: 2.3779 - val_acc: 0.7381\n",
      "Epoch 9/100\n",
      "370/370 [==============================] - 22s 58ms/step - loss: 2.3401 - acc: 0.9189 - val_loss: 2.3755 - val_acc: 0.7381\n",
      "Epoch 10/100\n",
      "370/370 [==============================] - 22s 59ms/step - loss: 2.3329 - acc: 0.9162 - val_loss: 2.3731 - val_acc: 0.7381\n",
      "Epoch 11/100\n",
      "370/370 [==============================] - 20s 55ms/step - loss: 2.3210 - acc: 0.8919 - val_loss: 2.3709 - val_acc: 0.7381\n",
      "Epoch 12/100\n",
      "370/370 [==============================] - 20s 53ms/step - loss: 2.3069 - acc: 0.9000 - val_loss: 2.3687 - val_acc: 0.7381\n",
      "Epoch 13/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.2986 - acc: 0.8838 - val_loss: 2.3665 - val_acc: 0.7143\n",
      "Epoch 14/100\n",
      "370/370 [==============================] - 20s 55ms/step - loss: 2.2834 - acc: 0.8946 - val_loss: 2.3645 - val_acc: 0.6905\n",
      "Epoch 15/100\n",
      "370/370 [==============================] - 20s 53ms/step - loss: 2.2705 - acc: 0.8757 - val_loss: 2.3624 - val_acc: 0.6905\n",
      "Epoch 16/100\n",
      "370/370 [==============================] - 23s 63ms/step - loss: 2.2713 - acc: 0.8378 - val_loss: 2.3600 - val_acc: 0.6905\n",
      "Epoch 17/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 2.2466 - acc: 0.8757 - val_loss: 2.3577 - val_acc: 0.6667\n",
      "Epoch 18/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.2340 - acc: 0.8541 - val_loss: 2.3555 - val_acc: 0.6667\n",
      "Epoch 19/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 2.2323 - acc: 0.8405 - val_loss: 2.3534 - val_acc: 0.6190\n",
      "Epoch 20/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 2.2148 - acc: 0.8568 - val_loss: 2.3515 - val_acc: 0.5952\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 23s 61ms/step - loss: 2.1985 - acc: 0.8514 - val_loss: 2.3497 - val_acc: 0.5952\n",
      "Epoch 22/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 2.1870 - acc: 0.8189 - val_loss: 2.3482 - val_acc: 0.5952\n",
      "Epoch 23/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 2.1750 - acc: 0.8405 - val_loss: 2.3465 - val_acc: 0.5952\n",
      "Epoch 24/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.1708 - acc: 0.8405 - val_loss: 2.3453 - val_acc: 0.5952\n",
      "Epoch 25/100\n",
      "370/370 [==============================] - 22s 59ms/step - loss: 2.1594 - acc: 0.8243 - val_loss: 2.3443 - val_acc: 0.5952\n",
      "Epoch 26/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 2.1453 - acc: 0.8378 - val_loss: 2.3432 - val_acc: 0.5714\n",
      "Epoch 27/100\n",
      "370/370 [==============================] - 23s 63ms/step - loss: 2.1462 - acc: 0.8162 - val_loss: 2.3422 - val_acc: 0.5714\n",
      "Epoch 28/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 2.1426 - acc: 0.8054 - val_loss: 2.3413 - val_acc: 0.5714\n",
      "Epoch 29/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.1283 - acc: 0.8189 - val_loss: 2.3405 - val_acc: 0.5714\n",
      "Epoch 30/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.1197 - acc: 0.8054 - val_loss: 2.3397 - val_acc: 0.5714\n",
      "Epoch 31/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 2.1053 - acc: 0.8135 - val_loss: 2.3390 - val_acc: 0.5714\n",
      "Epoch 32/100\n",
      "370/370 [==============================] - 23s 62ms/step - loss: 2.0895 - acc: 0.8216 - val_loss: 2.3382 - val_acc: 0.5714\n",
      "Epoch 33/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.0848 - acc: 0.8000 - val_loss: 2.3373 - val_acc: 0.5714\n",
      "Epoch 34/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 2.0775 - acc: 0.8054 - val_loss: 2.3362 - val_acc: 0.5714\n",
      "Epoch 35/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.0621 - acc: 0.8108 - val_loss: 2.3352 - val_acc: 0.5714\n",
      "Epoch 36/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 2.0513 - acc: 0.8081 - val_loss: 2.3342 - val_acc: 0.5714\n",
      "Epoch 37/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 2.0359 - acc: 0.8216 - val_loss: 2.3331 - val_acc: 0.5714\n",
      "Epoch 38/100\n",
      "370/370 [==============================] - 23s 62ms/step - loss: 2.0456 - acc: 0.7811 - val_loss: 2.3318 - val_acc: 0.5714\n",
      "Epoch 39/100\n",
      "370/370 [==============================] - 22s 58ms/step - loss: 2.0214 - acc: 0.8108 - val_loss: 2.3309 - val_acc: 0.5714\n",
      "Epoch 40/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.0130 - acc: 0.8054 - val_loss: 2.3298 - val_acc: 0.5714\n",
      "Epoch 41/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 2.0067 - acc: 0.8054 - val_loss: 2.3285 - val_acc: 0.5714\n",
      "Epoch 42/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 2.0166 - acc: 0.7757 - val_loss: 2.3273 - val_acc: 0.5476\n",
      "Epoch 43/100\n",
      "370/370 [==============================] - 23s 63ms/step - loss: 2.0149 - acc: 0.7892 - val_loss: 2.3262 - val_acc: 0.5476\n",
      "Epoch 44/100\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 1.9778 - acc: 0.8162 - val_loss: 2.3248 - val_acc: 0.5476\n",
      "Epoch 45/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.9977 - acc: 0.7784 - val_loss: 2.3227 - val_acc: 0.5476\n",
      "Epoch 46/100\n",
      "370/370 [==============================] - 20s 53ms/step - loss: 1.9965 - acc: 0.7757 - val_loss: 2.3207 - val_acc: 0.5476\n",
      "Epoch 47/100\n",
      "370/370 [==============================] - 20s 55ms/step - loss: 1.9751 - acc: 0.7919 - val_loss: 2.3178 - val_acc: 0.5476\n",
      "Epoch 48/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 1.9473 - acc: 0.8135 - val_loss: 2.3147 - val_acc: 0.5476\n",
      "Epoch 49/100\n",
      "370/370 [==============================] - 23s 62ms/step - loss: 1.9571 - acc: 0.8027 - val_loss: 2.3112 - val_acc: 0.5476\n",
      "Epoch 50/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 1.9443 - acc: 0.8054 - val_loss: 2.3076 - val_acc: 0.5476\n",
      "Epoch 51/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.9293 - acc: 0.7838 - val_loss: 2.3036 - val_acc: 0.5476\n",
      "Epoch 52/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.9446 - acc: 0.7730 - val_loss: 2.2997 - val_acc: 0.5476\n",
      "Epoch 53/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 1.9163 - acc: 0.7973 - val_loss: 2.2953 - val_acc: 0.5476\n",
      "Epoch 54/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.9180 - acc: 0.7811 - val_loss: 2.2917 - val_acc: 0.5476\n",
      "Epoch 55/100\n",
      "370/370 [==============================] - 23s 62ms/step - loss: 1.9054 - acc: 0.7676 - val_loss: 2.2875 - val_acc: 0.5476\n",
      "Epoch 56/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.9004 - acc: 0.7838 - val_loss: 2.2840 - val_acc: 0.5476\n",
      "Epoch 57/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.8835 - acc: 0.7784 - val_loss: 2.2812 - val_acc: 0.5476\n",
      "Epoch 58/100\n",
      "370/370 [==============================] - 22s 58ms/step - loss: 1.8695 - acc: 0.8000 - val_loss: 2.2779 - val_acc: 0.5476\n",
      "Epoch 59/100\n",
      "370/370 [==============================] - 22s 59ms/step - loss: 1.8865 - acc: 0.7595 - val_loss: 2.2749 - val_acc: 0.5476\n",
      "Epoch 60/100\n",
      "370/370 [==============================] - 23s 61ms/step - loss: 1.8628 - acc: 0.7892 - val_loss: 2.2720 - val_acc: 0.5476\n",
      "Epoch 61/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.8577 - acc: 0.7757 - val_loss: 2.2694 - val_acc: 0.5476\n",
      "Epoch 62/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 1.8559 - acc: 0.7811 - val_loss: 2.2663 - val_acc: 0.5476\n",
      "Epoch 63/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.8436 - acc: 0.7595 - val_loss: 2.2636 - val_acc: 0.5476\n",
      "Epoch 64/100\n",
      "370/370 [==============================] - 22s 60ms/step - loss: 1.8352 - acc: 0.7730 - val_loss: 2.2615 - val_acc: 0.5476\n",
      "Epoch 65/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.8524 - acc: 0.7541 - val_loss: 2.2592 - val_acc: 0.5476\n",
      "Epoch 66/100\n",
      "370/370 [==============================] - 23s 61ms/step - loss: 1.8394 - acc: 0.7432 - val_loss: 2.2572 - val_acc: 0.5476\n",
      "Epoch 67/100\n",
      "370/370 [==============================] - 22s 59ms/step - loss: 1.8060 - acc: 0.8135 - val_loss: 2.2560 - val_acc: 0.5476\n",
      "Epoch 68/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.7918 - acc: 0.8081 - val_loss: 2.2536 - val_acc: 0.5476\n",
      "Epoch 69/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.8170 - acc: 0.7541 - val_loss: 2.2511 - val_acc: 0.5476\n",
      "Epoch 70/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.8055 - acc: 0.7892 - val_loss: 2.2498 - val_acc: 0.5476\n",
      "Epoch 71/100\n",
      "370/370 [==============================] - 23s 62ms/step - loss: 1.7753 - acc: 0.8027 - val_loss: 2.2480 - val_acc: 0.5476\n",
      "Epoch 72/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.8023 - acc: 0.7568 - val_loss: 2.2458 - val_acc: 0.5476\n",
      "Epoch 73/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.7738 - acc: 0.7838 - val_loss: 2.2445 - val_acc: 0.5476\n",
      "Epoch 74/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.7679 - acc: 0.7919 - val_loss: 2.2429 - val_acc: 0.5476\n",
      "Epoch 75/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.7795 - acc: 0.8027 - val_loss: 2.2411 - val_acc: 0.5476\n",
      "Epoch 76/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.7840 - acc: 0.7811 - val_loss: 2.2397 - val_acc: 0.5476\n",
      "Epoch 77/100\n",
      "370/370 [==============================] - 22s 61ms/step - loss: 1.7815 - acc: 0.7568 - val_loss: 2.2380 - val_acc: 0.5476\n",
      "Epoch 78/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.7611 - acc: 0.7865 - val_loss: 2.2366 - val_acc: 0.5476\n",
      "Epoch 79/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.7537 - acc: 0.7946 - val_loss: 2.2350 - val_acc: 0.5476\n",
      "Epoch 80/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.7429 - acc: 0.7865 - val_loss: 2.2333 - val_acc: 0.5476\n",
      "Epoch 81/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.7632 - acc: 0.7784 - val_loss: 2.2316 - val_acc: 0.5476\n",
      "Epoch 82/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.7243 - acc: 0.8027 - val_loss: 2.2299 - val_acc: 0.5476\n",
      "Epoch 83/100\n",
      "370/370 [==============================] - 23s 62ms/step - loss: 1.7206 - acc: 0.8027 - val_loss: 2.2290 - val_acc: 0.5476\n",
      "Epoch 84/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.7540 - acc: 0.7919 - val_loss: 2.2277 - val_acc: 0.5476\n",
      "Epoch 85/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.7266 - acc: 0.7973 - val_loss: 2.2264 - val_acc: 0.5476\n",
      "Epoch 86/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.7187 - acc: 0.8027 - val_loss: 2.2246 - val_acc: 0.5476\n",
      "Epoch 87/100\n",
      "370/370 [==============================] - 22s 58ms/step - loss: 1.7264 - acc: 0.7811 - val_loss: 2.2236 - val_acc: 0.5476\n",
      "Epoch 88/100\n",
      "370/370 [==============================] - 23s 61ms/step - loss: 1.7119 - acc: 0.7973 - val_loss: 2.2221 - val_acc: 0.5476\n",
      "Epoch 89/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.7425 - acc: 0.7649 - val_loss: 2.2206 - val_acc: 0.5476\n",
      "Epoch 90/100\n",
      "370/370 [==============================] - 22s 59ms/step - loss: 1.7102 - acc: 0.7811 - val_loss: 2.2188 - val_acc: 0.5476\n",
      "Epoch 91/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.6948 - acc: 0.7973 - val_loss: 2.2179 - val_acc: 0.5476\n",
      "Epoch 92/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.7110 - acc: 0.7730 - val_loss: 2.2158 - val_acc: 0.5476\n",
      "Epoch 93/100\n",
      "370/370 [==============================] - 21s 58ms/step - loss: 1.6935 - acc: 0.7919 - val_loss: 2.2139 - val_acc: 0.5476\n",
      "Epoch 94/100\n",
      "370/370 [==============================] - 23s 61ms/step - loss: 1.6989 - acc: 0.7730 - val_loss: 2.2126 - val_acc: 0.5476\n",
      "Epoch 95/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.6604 - acc: 0.8216 - val_loss: 2.2115 - val_acc: 0.5476\n",
      "Epoch 96/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.6481 - acc: 0.8135 - val_loss: 2.2105 - val_acc: 0.5476\n",
      "Epoch 97/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.6776 - acc: 0.7973 - val_loss: 2.2088 - val_acc: 0.5476\n",
      "Epoch 98/100\n",
      "370/370 [==============================] - 21s 57ms/step - loss: 1.6670 - acc: 0.7892 - val_loss: 2.2078 - val_acc: 0.5476\n",
      "Epoch 99/100\n",
      "370/370 [==============================] - 21s 56ms/step - loss: 1.6421 - acc: 0.8027 - val_loss: 2.2061 - val_acc: 0.5476\n",
      "Epoch 100/100\n",
      "370/370 [==============================] - 23s 61ms/step - loss: 1.6693 - acc: 0.7838 - val_loss: 2.2044 - val_acc: 0.5476\n",
      "(412, 382593)\n",
      "Train on 370 samples, validate on 42 samples\n",
      "Epoch 1/100\n",
      "370/370 [==============================] - 42s 112ms/step - loss: 2.3976 - acc: 0.2405 - val_loss: 2.3971 - val_acc: 0.4048\n",
      "Epoch 2/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 2.3937 - acc: 0.8514 - val_loss: 2.3960 - val_acc: 0.5476\n",
      "Epoch 3/100\n",
      "370/370 [==============================] - 26s 70ms/step - loss: 2.3894 - acc: 0.8973 - val_loss: 2.3948 - val_acc: 0.5476\n",
      "Epoch 4/100\n",
      "370/370 [==============================] - 27s 74ms/step - loss: 2.3845 - acc: 0.9081 - val_loss: 2.3934 - val_acc: 0.5952\n",
      "Epoch 5/100\n",
      "370/370 [==============================] - 26s 70ms/step - loss: 2.3778 - acc: 0.9027 - val_loss: 2.3920 - val_acc: 0.5952\n",
      "Epoch 6/100\n",
      "370/370 [==============================] - 26s 70ms/step - loss: 2.3712 - acc: 0.9189 - val_loss: 2.3906 - val_acc: 0.6190\n",
      "Epoch 7/100\n",
      "370/370 [==============================] - 27s 72ms/step - loss: 2.3625 - acc: 0.9135 - val_loss: 2.3893 - val_acc: 0.6190\n",
      "Epoch 8/100\n",
      "370/370 [==============================] - 28s 75ms/step - loss: 2.3494 - acc: 0.9081 - val_loss: 2.3880 - val_acc: 0.5952\n",
      "Epoch 9/100\n",
      "370/370 [==============================] - 26s 69ms/step - loss: 2.3384 - acc: 0.9108 - val_loss: 2.3867 - val_acc: 0.5952\n",
      "Epoch 10/100\n",
      "370/370 [==============================] - 26s 70ms/step - loss: 2.3234 - acc: 0.8973 - val_loss: 2.3856 - val_acc: 0.5952\n",
      "Epoch 11/100\n",
      "370/370 [==============================] - 26s 70ms/step - loss: 2.3140 - acc: 0.8946 - val_loss: 2.3844 - val_acc: 0.5952\n",
      "Epoch 12/100\n",
      "370/370 [==============================] - 26s 70ms/step - loss: 2.2971 - acc: 0.8784 - val_loss: 2.3833 - val_acc: 0.5952\n",
      "Epoch 13/100\n",
      "370/370 [==============================] - 27s 74ms/step - loss: 2.2871 - acc: 0.8784 - val_loss: 2.3824 - val_acc: 0.5952\n",
      "Epoch 14/100\n",
      "370/370 [==============================] - 26s 70ms/step - loss: 2.2734 - acc: 0.8676 - val_loss: 2.3814 - val_acc: 0.5714\n",
      "Epoch 15/100\n",
      "370/370 [==============================] - 25s 68ms/step - loss: 2.2677 - acc: 0.8703 - val_loss: 2.3803 - val_acc: 0.5714\n",
      "Epoch 16/100\n",
      "370/370 [==============================] - 26s 71ms/step - loss: 2.2622 - acc: 0.8541 - val_loss: 2.3795 - val_acc: 0.5714\n",
      "Epoch 17/100\n",
      "370/370 [==============================] - 27s 74ms/step - loss: 2.2456 - acc: 0.8405 - val_loss: 2.3787 - val_acc: 0.5476\n",
      "Epoch 18/100\n",
      "370/370 [==============================] - 26s 70ms/step - loss: 2.2474 - acc: 0.8405 - val_loss: 2.3780 - val_acc: 0.5476\n",
      "Epoch 19/100\n",
      "370/370 [==============================] - 25s 68ms/step - loss: 2.2322 - acc: 0.8243 - val_loss: 2.3772 - val_acc: 0.5476\n",
      "Epoch 20/100\n",
      "370/370 [==============================] - 26s 70ms/step - loss: 2.2141 - acc: 0.8459 - val_loss: 2.3765 - val_acc: 0.5476\n",
      "Epoch 21/100\n",
      "370/370 [==============================] - 26s 69ms/step - loss: 2.2121 - acc: 0.8135 - val_loss: 2.3757 - val_acc: 0.5476\n",
      "Epoch 22/100\n",
      "370/370 [==============================] - 27s 74ms/step - loss: 2.1989 - acc: 0.8135 - val_loss: 2.3750 - val_acc: 0.5476\n",
      "Epoch 23/100\n",
      "370/370 [==============================] - 26s 71ms/step - loss: 2.1781 - acc: 0.8216 - val_loss: 2.3745 - val_acc: 0.5476\n",
      "Epoch 24/100\n",
      "370/370 [==============================] - 26s 71ms/step - loss: 2.1811 - acc: 0.8351 - val_loss: 2.3740 - val_acc: 0.5238\n",
      "Epoch 25/100\n",
      "370/370 [==============================] - 26s 71ms/step - loss: 2.1750 - acc: 0.8027 - val_loss: 2.3734 - val_acc: 0.4762\n",
      "Epoch 26/100\n",
      "370/370 [==============================] - 27s 73ms/step - loss: 2.1588 - acc: 0.8054 - val_loss: 2.3730 - val_acc: 0.4762\n",
      "Epoch 27/100\n",
      "370/370 [==============================] - 15343s 41s/step - loss: 2.1506 - acc: 0.8000 - val_loss: 2.3721 - val_acc: 0.4762\n",
      "Epoch 28/100\n",
      "370/370 [==============================] - 31s 84ms/step - loss: 2.1332 - acc: 0.8135 - val_loss: 2.3715 - val_acc: 0.4762\n",
      "Epoch 29/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 2.1138 - acc: 0.8216 - val_loss: 2.3707 - val_acc: 0.4762\n",
      "Epoch 30/100\n",
      "370/370 [==============================] - 36s 96ms/step - loss: 2.1237 - acc: 0.7946 - val_loss: 2.3701 - val_acc: 0.4762\n",
      "Epoch 31/100\n",
      "370/370 [==============================] - 30s 80ms/step - loss: 2.1173 - acc: 0.7838 - val_loss: 2.3696 - val_acc: 0.4762\n",
      "Epoch 32/100\n",
      "370/370 [==============================] - 32s 87ms/step - loss: 2.1064 - acc: 0.7865 - val_loss: 2.3693 - val_acc: 0.4762\n",
      "Epoch 33/100\n",
      "370/370 [==============================] - 31s 84ms/step - loss: 2.1173 - acc: 0.7622 - val_loss: 2.3685 - val_acc: 0.4762\n",
      "Epoch 34/100\n",
      "370/370 [==============================] - 31s 83ms/step - loss: 2.0786 - acc: 0.7811 - val_loss: 2.3679 - val_acc: 0.4762\n",
      "Epoch 35/100\n",
      "370/370 [==============================] - 32s 86ms/step - loss: 2.0641 - acc: 0.7973 - val_loss: 2.3673 - val_acc: 0.4762\n",
      "Epoch 36/100\n",
      "370/370 [==============================] - 32s 85ms/step - loss: 2.0775 - acc: 0.7622 - val_loss: 2.3666 - val_acc: 0.4762\n",
      "Epoch 37/100\n",
      "370/370 [==============================] - 30s 82ms/step - loss: 2.0493 - acc: 0.7730 - val_loss: 2.3658 - val_acc: 0.4762\n",
      "Epoch 38/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 2.0556 - acc: 0.7595 - val_loss: 2.3653 - val_acc: 0.4762\n",
      "Epoch 39/100\n",
      "370/370 [==============================] - 31s 83ms/step - loss: 2.0465 - acc: 0.7703 - val_loss: 2.3647 - val_acc: 0.4762\n",
      "Epoch 40/100\n",
      "370/370 [==============================] - 31s 83ms/step - loss: 2.0280 - acc: 0.7946 - val_loss: 2.3640 - val_acc: 0.4762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "370/370 [==============================] - 32s 87ms/step - loss: 2.0231 - acc: 0.7784 - val_loss: 2.3629 - val_acc: 0.4762\n",
      "Epoch 42/100\n",
      "370/370 [==============================] - 30s 81ms/step - loss: 2.0125 - acc: 0.7784 - val_loss: 2.3615 - val_acc: 0.4762\n",
      "Epoch 43/100\n",
      "370/370 [==============================] - 30s 81ms/step - loss: 2.0090 - acc: 0.7703 - val_loss: 2.3605 - val_acc: 0.4762\n",
      "Epoch 44/100\n",
      "370/370 [==============================] - 30s 81ms/step - loss: 1.9877 - acc: 0.7946 - val_loss: 2.3598 - val_acc: 0.4762\n",
      "Epoch 45/100\n",
      "370/370 [==============================] - 30s 82ms/step - loss: 2.0234 - acc: 0.7324 - val_loss: 2.3590 - val_acc: 0.4762\n",
      "Epoch 46/100\n",
      "370/370 [==============================] - 33s 89ms/step - loss: 1.9869 - acc: 0.7730 - val_loss: 2.3582 - val_acc: 0.4762\n",
      "Epoch 47/100\n",
      "370/370 [==============================] - 30s 81ms/step - loss: 1.9987 - acc: 0.7622 - val_loss: 2.3574 - val_acc: 0.4762\n",
      "Epoch 48/100\n",
      "370/370 [==============================] - 30s 81ms/step - loss: 1.9802 - acc: 0.7649 - val_loss: 2.3560 - val_acc: 0.4762\n",
      "Epoch 49/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.9494 - acc: 0.7757 - val_loss: 2.3545 - val_acc: 0.4762\n",
      "Epoch 50/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.9591 - acc: 0.7649 - val_loss: 2.3530 - val_acc: 0.4762\n",
      "Epoch 51/100\n",
      "370/370 [==============================] - 31s 84ms/step - loss: 1.9438 - acc: 0.7622 - val_loss: 2.3516 - val_acc: 0.4762\n",
      "Epoch 52/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.9346 - acc: 0.7811 - val_loss: 2.3503 - val_acc: 0.4762\n",
      "Epoch 53/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.9295 - acc: 0.7730 - val_loss: 2.3485 - val_acc: 0.4762\n",
      "Epoch 54/100\n",
      "370/370 [==============================] - 30s 80ms/step - loss: 1.9296 - acc: 0.7676 - val_loss: 2.3464 - val_acc: 0.4762\n",
      "Epoch 55/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.9064 - acc: 0.7757 - val_loss: 2.3444 - val_acc: 0.4762\n",
      "Epoch 56/100\n",
      "370/370 [==============================] - 32s 86ms/step - loss: 1.9116 - acc: 0.7595 - val_loss: 2.3420 - val_acc: 0.4762\n",
      "Epoch 57/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.9197 - acc: 0.7622 - val_loss: 2.3395 - val_acc: 0.4524\n",
      "Epoch 58/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.8851 - acc: 0.7946 - val_loss: 2.3376 - val_acc: 0.4524\n",
      "Epoch 59/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.8841 - acc: 0.7595 - val_loss: 2.3358 - val_acc: 0.4762\n",
      "Epoch 60/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.8907 - acc: 0.7676 - val_loss: 2.3334 - val_acc: 0.4762\n",
      "Epoch 61/100\n",
      "370/370 [==============================] - 31s 84ms/step - loss: 1.8790 - acc: 0.7757 - val_loss: 2.3307 - val_acc: 0.4762\n",
      "Epoch 62/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.8690 - acc: 0.7649 - val_loss: 2.3288 - val_acc: 0.4762\n",
      "Epoch 63/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.8852 - acc: 0.7595 - val_loss: 2.3262 - val_acc: 0.4762\n",
      "Epoch 64/100\n",
      "370/370 [==============================] - 29s 77ms/step - loss: 1.8653 - acc: 0.7514 - val_loss: 2.3239 - val_acc: 0.4762\n",
      "Epoch 65/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.8562 - acc: 0.7541 - val_loss: 2.3217 - val_acc: 0.4524\n",
      "Epoch 66/100\n",
      "370/370 [==============================] - 28s 77ms/step - loss: 1.8363 - acc: 0.7838 - val_loss: 2.3201 - val_acc: 0.4762\n",
      "Epoch 67/100\n",
      "370/370 [==============================] - 32s 86ms/step - loss: 1.8524 - acc: 0.7514 - val_loss: 2.3176 - val_acc: 0.4524\n",
      "Epoch 68/100\n",
      "370/370 [==============================] - 28s 77ms/step - loss: 1.8286 - acc: 0.7811 - val_loss: 2.3160 - val_acc: 0.4762\n",
      "Epoch 69/100\n",
      "370/370 [==============================] - 35s 96ms/step - loss: 1.8262 - acc: 0.7649 - val_loss: 2.3140 - val_acc: 0.4762\n",
      "Epoch 70/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.8117 - acc: 0.7757 - val_loss: 2.3121 - val_acc: 0.4762\n",
      "Epoch 71/100\n",
      "370/370 [==============================] - 30s 82ms/step - loss: 1.8046 - acc: 0.7649 - val_loss: 2.3101 - val_acc: 0.4762\n",
      "Epoch 72/100\n",
      "370/370 [==============================] - 30s 80ms/step - loss: 1.8189 - acc: 0.7622 - val_loss: 2.3081 - val_acc: 0.4524\n",
      "Epoch 73/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.8154 - acc: 0.7405 - val_loss: 2.3066 - val_acc: 0.4762\n",
      "Epoch 74/100\n",
      "370/370 [==============================] - 28s 77ms/step - loss: 1.7936 - acc: 0.7649 - val_loss: 2.3050 - val_acc: 0.4762\n",
      "Epoch 75/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.7592 - acc: 0.8000 - val_loss: 2.3035 - val_acc: 0.4524\n",
      "Epoch 76/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.8052 - acc: 0.7486 - val_loss: 2.3013 - val_acc: 0.4762\n",
      "Epoch 77/100\n",
      "370/370 [==============================] - 31s 84ms/step - loss: 1.7858 - acc: 0.7649 - val_loss: 2.2992 - val_acc: 0.4762\n",
      "Epoch 78/100\n",
      "370/370 [==============================] - 29s 77ms/step - loss: 1.7802 - acc: 0.7514 - val_loss: 2.2970 - val_acc: 0.4762\n",
      "Epoch 79/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.7761 - acc: 0.7568 - val_loss: 2.2953 - val_acc: 0.4762\n",
      "Epoch 80/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.7563 - acc: 0.7811 - val_loss: 2.2943 - val_acc: 0.4762\n",
      "Epoch 81/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.7650 - acc: 0.7541 - val_loss: 2.2930 - val_acc: 0.4762\n",
      "Epoch 82/100\n",
      "370/370 [==============================] - 31s 83ms/step - loss: 1.7662 - acc: 0.7405 - val_loss: 2.2910 - val_acc: 0.4762\n",
      "Epoch 83/100\n",
      "370/370 [==============================] - 29s 78ms/step - loss: 1.7336 - acc: 0.7919 - val_loss: 2.2887 - val_acc: 0.4762\n",
      "Epoch 84/100\n",
      "370/370 [==============================] - 31s 83ms/step - loss: 1.7586 - acc: 0.7297 - val_loss: 2.2861 - val_acc: 0.4762\n",
      "Epoch 85/100\n",
      "370/370 [==============================] - 29s 80ms/step - loss: 1.7515 - acc: 0.7649 - val_loss: 2.2846 - val_acc: 0.4762\n",
      "Epoch 86/100\n",
      "370/370 [==============================] - 30s 82ms/step - loss: 1.7256 - acc: 0.7703 - val_loss: 2.2828 - val_acc: 0.4762\n",
      "Epoch 87/100\n",
      "370/370 [==============================] - 33s 89ms/step - loss: 1.7351 - acc: 0.7568 - val_loss: 2.2804 - val_acc: 0.4762\n",
      "Epoch 88/100\n",
      "370/370 [==============================] - 30s 82ms/step - loss: 1.7212 - acc: 0.7838 - val_loss: 2.2783 - val_acc: 0.4762\n",
      "Epoch 89/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.7134 - acc: 0.7784 - val_loss: 2.2769 - val_acc: 0.4762\n",
      "Epoch 90/100\n",
      "370/370 [==============================] - 27s 74ms/step - loss: 1.7064 - acc: 0.7703 - val_loss: 2.2750 - val_acc: 0.4762\n",
      "Epoch 91/100\n",
      "370/370 [==============================] - 28s 75ms/step - loss: 1.7348 - acc: 0.7405 - val_loss: 2.2730 - val_acc: 0.4762\n",
      "Epoch 92/100\n",
      "370/370 [==============================] - 30s 81ms/step - loss: 1.7359 - acc: 0.7649 - val_loss: 2.2709 - val_acc: 0.4762\n",
      "Epoch 93/100\n",
      "370/370 [==============================] - 29s 77ms/step - loss: 1.6736 - acc: 0.7892 - val_loss: 2.2700 - val_acc: 0.4762\n",
      "Epoch 94/100\n",
      "370/370 [==============================] - 27s 74ms/step - loss: 1.6755 - acc: 0.7865 - val_loss: 2.2685 - val_acc: 0.4762\n",
      "Epoch 95/100\n",
      "370/370 [==============================] - 33s 89ms/step - loss: 1.7014 - acc: 0.7838 - val_loss: 2.2669 - val_acc: 0.4762\n",
      "Epoch 96/100\n",
      "370/370 [==============================] - 39s 106ms/step - loss: 1.6994 - acc: 0.7541 - val_loss: 2.2647 - val_acc: 0.4762\n",
      "Epoch 97/100\n",
      "370/370 [==============================] - 36s 96ms/step - loss: 1.6730 - acc: 0.7757 - val_loss: 2.2635 - val_acc: 0.4762\n",
      "Epoch 98/100\n",
      "370/370 [==============================] - 31s 83ms/step - loss: 1.6939 - acc: 0.7622 - val_loss: 2.2621 - val_acc: 0.4762\n",
      "Epoch 99/100\n",
      "370/370 [==============================] - 35s 94ms/step - loss: 1.6606 - acc: 0.7919 - val_loss: 2.2600 - val_acc: 0.4762\n",
      "Epoch 100/100\n",
      "370/370 [==============================] - 29s 79ms/step - loss: 1.6851 - acc: 0.7784 - val_loss: 2.2585 - val_acc: 0.4762\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in training_data:\n",
    "    print(i['document_matrix'].shape)\n",
    "    model = simple_ffn(i['document_matrix'], i['labels'])\n",
    "    model.fit(i['document_matrix'], i['labels'], epochs=100, validation_split=0.1)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(os.path.join(MODELS_PATH,'ffn_sample_model_sentences_bi.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on unseen data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in training_data:\n",
    "    X_test, y_test = prepare_test_data(corpora_test, labels_test, i['pipeline_instance'])\n",
    "    test_data.append({'X_test': X_test, 'y_test': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>$</th>\n",
       "      <th>%</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>...</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>{</th>\n",
       "      <th>|</th>\n",
       "      <th>}</th>\n",
       "      <th>~</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.351427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080407</td>\n",
       "      <td>0.080444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168340</td>\n",
       "      <td>0.118161</td>\n",
       "      <td>0.178917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.268115</td>\n",
       "      <td>0.121792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038955</td>\n",
       "      <td>0.054692</td>\n",
       "      <td>0.066025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.231594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188653</td>\n",
       "      <td>0.151879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075985</td>\n",
       "      <td>0.065340</td>\n",
       "      <td>0.065370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336291</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>0.054718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087234</td>\n",
       "      <td>0.070230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               !    \"    #    $    %    &         '         (         ) ...   \\\n",
       "0  0.351427  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.080407  0.080444 ...    \n",
       "1  0.531607  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000 ...    \n",
       "2  0.470930  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000 ...    \n",
       "3  0.231594  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000 ...    \n",
       "4  0.380765  0.0  0.0  0.0  0.0  0.0  0.0  0.075985  0.065340  0.065370 ...    \n",
       "\n",
       "          u         v         w         x         y         z    {    |    }  \\\n",
       "0  0.198643  0.000000  0.168340  0.118161  0.178917  0.000000  0.0  0.0  0.0   \n",
       "1  0.037561  0.000000  0.038198  0.268115  0.121792  0.000000  0.0  0.0  0.0   \n",
       "2  0.038955  0.054692  0.066025  0.000000  0.014035  0.000000  0.0  0.0  0.0   \n",
       "3  0.087272  0.000000  0.266251  0.000000  0.188653  0.151879  0.0  0.0  0.0   \n",
       "4  0.336291  0.018886  0.054718  0.000000  0.087234  0.070230  0.0  0.0  0.0   \n",
       "\n",
       "     ~  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]['X_test'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>af</th>\n",
       "      <th>en</th>\n",
       "      <th>nr</th>\n",
       "      <th>nso</th>\n",
       "      <th>ss</th>\n",
       "      <th>st</th>\n",
       "      <th>tn</th>\n",
       "      <th>ts</th>\n",
       "      <th>ve</th>\n",
       "      <th>xh</th>\n",
       "      <th>zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34750</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13655</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21978</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       af  en  nr  nso  ss  st  tn  ts  ve  xh  zu\n",
       "34750   0   0   0    0   0   0   0   0   0   1   0\n",
       "18986   0   0   0    1   0   0   0   0   0   0   0\n",
       "13655   0   1   0    0   0   0   0   0   0   0   0\n",
       "15126   0   0   1    0   0   0   0   0   0   0   0\n",
       "21978   0   0   0    0   1   0   0   0   0   0   0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]['y_test'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238/1238 [==============================] - 2s 2ms/step\n",
      "Model test accuracy 87.24\n",
      "1238/1238 [==============================] - 15s 12ms/step\n",
      "Model test accuracy 68.34\n",
      "1238/1238 [==============================] - 25s 20ms/step\n",
      "Model test accuracy 55.98\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(test_data):\n",
    "    score, accuracy = models[idx].evaluate(i['X_test'], i['y_test'])\n",
    "    print('Model test accuracy', accuracy.round(4)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sa_lang",
   "language": "python",
   "name": "sa_lang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
